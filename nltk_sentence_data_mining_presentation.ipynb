{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Sentence Data Mining\n",
    "This notebook provides a procedure for mining sentences from a text-based corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The module `os` enables navigation of the computer's file system.\n",
    "2. `PlaintextCorpusReader` from `nltk.corpus` makes it possible to load a text-based corpus.\n",
    "3. `TokenSearcher` from `nltk.text` enables corpus searches.\n",
    "4. `FreqDist` from `nltk` allows us to see how much of each element occurs in a given situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.text import TokenSearcher\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load text-based corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line below navigates to the folder where the corpus is stored.\n",
    "\n",
    "The second line uses `PlaintextCorpusReader` to load the text-based corpus so we can search it. The parameter `'.'` tells the computer to find the files in the currently selected folder, and `'.*'` indicates that every file in the folder should be selected. `.sents()` tells the corpus reader to load the documents as a list of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser(os.path.join('~', 'sch_corpus')))\n",
    "\n",
    "hmong = PlaintextCorpusReader('.', '.*').sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step takes the sentence-based list and turns it into a single list of words, while adding sentence numbers in the format `@@[number]@@`. This enables `TokenSearcher` to search the examples, as it needs a list of words—not a list of sentences—to process. We use `word.lower()` below to ensure every word has the same format (all lowercase), which will make it easier to do searches later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmong_words = []\n",
    "for i, line in enumerate(hmong):\n",
    "    hmong_words.append(\"@@\"+str(i)+\"@@\")\n",
    "    for word in line:\n",
    "        hmong_words.append(word.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the words into a TokenSearcher object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = TokenSearcher(hmong_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, a wide array of options are available for searching. Here, we will do three different searches: \n",
    "1. a search checking which verbs commonly appear after certain grammatical markers, \n",
    "2. a search between a free and a bound root to see what intensifiers can go in between, and\n",
    "3. an informal test for co-occurrence between two elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grammatical markers and verbs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `findall` as a method of our `TokenSearcher` object to find instances of what we are looking for in the corpus. Each word searched should be enclosed in angle brackets, and any matching word can be indicated by the regular expression `.*`. Below, we do a search for elements—which will primarily be verbs—following the Hmong irrealis marker + modal sequence _yuav tsum_ 'must'. The parentheses indicate that we want to keep only the matching elements after `<yuav><tsum>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = searcher.findall('<yuav><tsum>(<.*>)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make a FreqDist object containing our results, selecting the single word in each instance in `out` that matches our search above. We can use the method `.most_common(50)` to get the 50 most common elements following _yuav tsum_ 'must'. As it turns out, apart from three grammatical elements—_tau_ 'have to', _tsis_ 'negative marker', and the verbal prefix _sib-_ 'associative-reciprocal'—every item found is a verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tau', 2547), ('yog', 1948), ('muaj', 1467), ('ua', 826), ('paub', 729), ('muab', 440), ('mus', 397), ('hais', 379), ('tsis', 241), ('los', 181), ('siv', 177), ('sib', 171), ('coj', 169), ('tuaj', 160), ('txawj', 158), ('saib', 129), ('xav', 126), ('nyob', 124), ('cia', 120), ('raug', 108), ('kom', 105), ('tsi', 103), ('txhob', 103), ('hlub', 101), ('pab', 100), ('to', 98), ('rov', 90), ('nrhiav', 88), ('moog', 86), ('xyaum', 79), ('zoo', 79), ('noj', 76), ('has', 76), ('yuav', 76), ('tig', 76), ('pom', 76), ('kawm', 75), ('tso', 72), ('tawm', 72), ('nco', 68), ('cias', 56), ('mloog', 54), ('hu', 54), ('hloov', 54), ('sau', 54), ('qhia', 54), ('nrog', 52), ('them', 51), ('pib', 50), ('tua', 49)]\n"
     ]
    }
   ],
   "source": [
    "fd = FreqDist(w[0] for w in out)\n",
    "print(fd.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Free roots, bound roots, and intensifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to see which intensifier prefixes/infixes (depending on the analysis) can occur between a verb that can appear as a free root, and a bound root that commonly attaches to it. Let's look at _l(i)ab_ 'red' with the bound root _ploog_. The question mark in `<li?ab>` here indicates that we want 0-1 instances of `i`, reflecting differences of dialect common in Hmong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = searcher.findall('<li?ab>(<.*>)<ploog>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again here, we create a FreqDist object, and check the results. `.most_common(10)` is used as not many intensifier prefixes/infixes are expected in advance to be possible. Note that typos are quite common in natural text data: `gab` should be `qab`, meaning that the true number of total instances of `qab` is 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('qab', 17), ('plwb', 9), ('qaab', 4), ('quas', 1), ('plawb', 1), ('gab', 1)]\n"
     ]
    }
   ],
   "source": [
    "fd = FreqDist(w[0] for w in out)\n",
    "print(fd.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Informal test for co-occurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to see which verbs can co-occur with the modifier _tsem tsawv_ or _tsim tsawv_ 'somewhat'. We use `<ts[ei]m>` below to indicate that we want either _tsem_ or _tsim_—the square brackets indicate a choice of one or the other item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = searcher.findall('(<.*>)<ts[ei]m><tsawv>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we create a FreqDist object, and check the 100 top instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('paub', 10), ('koj', 7), ('kuv', 5), ('vwm', 4), ('tau', 4), ('zoo', 4), ('liab', 3), ('ntseeg', 3), ('nco', 3), ('plab', 2), ('nws', 2), ('khib', 2), ('siab', 2), ('thooj', 2), ('kaj', 2), ('miskas', 2), ('ntshai', 2), ('cai', 2), ('ze', 2), ('tub', 2), ('xav', 2), ('pyramid', 1), ('khibxeeb', 1), ('nkauj', 1), ('ntawd', 1), ('xib', 1), ('xws', 1), ('xwm', 1), ('lauv', 1), ('indigenous', 1), ('mob', 1), ('pau', 1), ('tuag', 1), ('ko', 1), ('vaajtswv', 1), ('taws', 1), ('hais', 1), ('caws', 1), ('kis', 1), ('yog', 1), ('funny', 1), ('dlhos', 1), ('neej', 1), ('lauj', 1), ('yawmyij', 1), ('rog', 1), ('ris', 1), ('kev', 1), ('tuaj', 1), ('mental', 1), ('hlwb', 1), ('taub', 1), ('qab', 1), ('qub', 1), ('personal', 1), ('no', 1), ('muag', 1), ('pom', 1), ('saub', 1), ('ke', 1), ('crazy', 1), ('tshauv', 1)]\n"
     ]
    }
   ],
   "source": [
    "fd = FreqDist(w[0] for w in out)\n",
    "print(fd.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, there is a lot of noise, given that _tsem/tsim tsawv_ can allow a noun phrase to come in between it and the verb it modifies. Nevertheless, we see a pattern among verbs: _paub_ 'know', _ntseeg_ 'believe', _nco_ 'remember', _xav_ 'want', _vwm_ 'be crazy', _zoo_ 'be good', and _liab_ 'be red' suggest a pattern where verbs of cognition and stative verbs are the most common to be involved in this construction.\n",
    "\n",
    "Now, let's ask the question: are action verbs typically involved in this construction, such as _khiav_ 'run' or _kawm_ 'study'? Let's allow an optional additional word to appear in between if it's a pronoun. We insert the desired test verb in the first word slot, and here we test four action verbs: _khiav_ 'run', _kawm_ 'study', _noj_ 'eat', and _mus_ 'go'. The additional optional pronoun is introduced by `(?:` followed by each Hmong pronoun in angle brackets and a final parenthesis `)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optional_pronoun = '(?:<kuv>|<koj>|<nws>|<nwg>|<wb>|<ib>|<neb>|<meb>|<nkawv>|<peb>|<nej>|<mej>|<lawv>|<paub>|<yus>|<luag>)'\n",
    "khiav = searcher.findall('<khiav>' + optional_pronoun + '<ts[ei]m><tsawv>')\n",
    "kawm = searcher.findall('<kawm>' + optional_pronoun + '<ts[ei]m><tsawv>')\n",
    "noj = searcher.findall('<noj>' + optional_pronoun + '<ts[ei]m><tsawv>')\n",
    "mus = searcher.findall('<mus>' + optional_pronoun + '<ts[ei]m><tsawv>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all we need to do is see how many matches we have, and that will tell us whether the four action verbs are normal in this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(khiav))\n",
    "print(len(kawm))\n",
    "print(len(noj))\n",
    "print(len(mus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results confirm that _khiav_ 'run', _kawm_ 'study', _noj_ 'eat', and _mus_ 'go' do not co-occur with _tsem/tsim tsawv_ in our corpus, with or without a pronoun in between. This, combined with the severe paucity of activon verbs attested in the `most_common` list above—limited to single instances of _tuag_ 'die' or _tuaj_ 'come' (which might actually be accompanying a verb of cognition in the corpus), for example—suggest that action verbs are very limited as a class in this construction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
